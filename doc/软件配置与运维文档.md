# 基于IDM-VTON的虚拟试穿系统 - 软件配置与运维文档

项目负责人: 熊彦钧、李锐钊、罗斯、吴深荣

## 1. 配置管理

### 1.1 环境配置

#### 1.1.1 系统要求

- Python 3.10+
- CUDA 11.8+
- PyTorch 2.0.1+
- 内存: 16GB+ (推荐32GB)
- 显存: 8GB+ (推荐24GB)

#### 1.1.2 环境变量配置

```bash
# .env文件
FLASK_ENV=development
FLASK_DEBUG=True
SECRET_KEY=your-secret-key-here

# 数据库配置
DATABASE_URL=sqlite:///image_database.db

# AI模型配置
MODEL_PATH=/root/autodl-tmp/IDM-VTON/ckpt
DIFFUSION_MODEL_PATH=yisol/IDM-VTON

# 推理配置
INFERENCE_STEPS=30
GUIDANCE_SCALE=2.0
CLOTH_GUIDANCE_SCALE=2.5

# GPU配置
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# 安全配置
UPLOAD_MAX_SIZE=10485760  # 10MB
ALLOWED_EXTENSIONS=png,jpg,jpeg,gif,webp
```

#### 1.1.3 生产环境配置

```bash
# 生产环境变量
FLASK_ENV=production
FLASK_DEBUG=False
SECRET_KEY=production-secret-key

# 性能配置
WORKERS=4
TIMEOUT=300
MAX_REQUESTS=1000

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=/var/log/aitryqon/app.log
```

### 1.2 依赖管理

#### 1.2.1 Python依赖

```
# 深度学习框架
torch==2.0.1
torchvision==0.15.2
pytorch-cuda==11.8

# Diffusion模型相关
diffusers==0.25.0
transformers==4.36.2
accelerate==0.25.0

# 服务器框架
Flask==2.3.3
gunicorn==21.2.0
gradio==3.44.0

# 图像处理
Pillow==10.0.1
opencv-python==4.8.0.74

# 工具库
requests==2.31.0
python-dotenv==1.0.0
numpy==1.24.3
```

#### 1.2.2 开发依赖

```
# 测试框架
pytest==7.4.0
pytest-flask==1.2.0

# 代码质量
black==23.7.0
flake8==6.0.0
mypy==1.5.1

# 性能分析
line_profiler==4.0.2
memory_profiler==0.61.0
```

### 1.3 配置文件管理

#### 1.3.1 应用配置

```python
# config/default.py
import os
from datetime import timedelta

class Config:
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key'
    DATABASE_URL = os.environ.get('DATABASE_URL') or 'sqlite:///image_database.db'
    UPLOAD_FOLDER = 'saved_images'
    MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB
  
    # 模型配置
    MODEL_PATH = os.environ.get('MODEL_PATH') or '/root/autodl-tmp/IDM-VTON/ckpt'
    INFERENCE_STEPS = int(os.environ.get('INFERENCE_STEPS') or 30)
    GUIDANCE_SCALE = float(os.environ.get('GUIDANCE_SCALE') or 2.0)
  
    # GPU配置
    CUDA_VISIBLE_DEVICES = os.environ.get('CUDA_VISIBLE_DEVICES') or '0'
    PYTORCH_CUDA_ALLOC_CONF = os.environ.get('PYTORCH_CUDA_ALLOC_CONF') or 'max_split_size_mb:512'
```

#### 1.3.2 数据库配置

```python
# database_config.py
import sqlite3
from pathlib import Path

class DatabaseConfig:
    def __init__(self, db_path):
        self.db_path = db_path
        self.ensure_db_exists()
  
    def ensure_db_exists(self):
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
  
    def get_connection(self):
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn
```

#### 1.3.3 GPU配置

```python
# gpu_config.py
import torch
import os

class GPUConfig:
    def __init__(self):
        self.device = self._get_device()
    
    def _get_device(self):
        if torch.cuda.is_available():
            gpu_id = os.environ.get('CUDA_VISIBLE_DEVICES', '0')
            return f'cuda:{gpu_id}'
        return 'cpu'
  
    def optimize_memory(self):
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
```

## 2. 版本控制

### 2.1 Git工作流

#### 2.1.1 分支策略

```
master (主分支)
├── develop (开发分支)
│   ├── feature/功能名称
│   ├── bugfix/问题描述
│   └── hotfix/紧急修复
└── release/版本号
```

#### 2.1.2 提交规范

```
<type>(<scope>): <subject>

类型定义:
- feat: 新功能
- fix: 修复bug
- docs: 文档更新
- style: 代码格式化
- refactor: 重构代码
- test: 测试相关
- chore: 构建或工具变动
```

### 2.2 版本管理

#### 2.2.1 版本号规范

采用语义化版本控制 (SemVer):

```
MAJOR.MINOR.PATCH
```

#### 2.2.2 版本发布流程

```bash
# 1. 创建发布分支
git checkout -b release/v1.1.0 develop

# 2. 更新版本号
echo "1.1.0" > VERSION

# 3. 合并到主分支
git checkout master
git merge --no-ff release/v1.1.0
git tag -a v1.1.0 -m "Release version 1.1.0"

# 4. 回合并到开发分支
git checkout develop
git merge --no-ff release/v1.1.0
```

### 2.3 代码质量控制

#### 2.3.1 代码审查

**PR检查清单**:

- [ ] 代码符合项目规范
- [ ] 添加了适当的测试
- [ ] 更新了相关文档
- [ ] 无安全漏洞

#### 2.3.2 自动化检查

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.7.0
    hooks:
      - id: black
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        args: [--max-line-length=88]
```

## 3. 持续集成

### 3.1 CI/CD流水线

#### 3.1.1 GitHub Actions配置

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ master, develop ]
  pull_request:
    branches: [ master ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: 3.10
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest
    - name: Run tests
      run: pytest tests/

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master'
    steps:
    - uses: actions/checkout@v3
    - name: Build Docker image
      run: |
        docker build -t ai-tryon:latest .
        docker tag ai-tryon:latest ai-tryon:${{ github.sha }}
```

#### 3.1.2 质量门禁

```yaml
quality:
  runs-on: ubuntu-latest
  steps:
  - uses: actions/checkout@v3
  - name: Run Black
    run: black --check app/
  - name: Run Flake8
    run: flake8 app/
  - name: Security scan
    uses: pypa/gh-action-pip-audit@v1.0.8
```

### 3.2 自动化测试

#### 3.2.1 测试结构

```
tests/
├── conftest.py
├── test_app.py
├── test_database.py
├── test_auth.py
└── test_ai_tryon.py
```

#### 3.2.2 测试配置

```python
# conftest.py
import pytest
from app import create_app

@pytest.fixture
def app():
    app = create_app({'TESTING': True})
    yield app

@pytest.fixture
def client(app):
    return app.test_client()
```

## 4. 部署策略

### 4.1 环境管理

#### 4.1.1 环境分类

- **开发环境**: 日常开发和功能测试
- **测试环境**: 集成测试和性能测试
- **预生产环境**: 发布前最终验证
- **生产环境**: 正式服务用户

#### 4.1.2 环境配置

```bash
# 开发环境
FLASK_ENV=development
FLASK_DEBUG=True
DATABASE_URL=sqlite:///dev_database.db

# 生产环境
FLASK_ENV=production
FLASK_DEBUG=False
DATABASE_URL=postgresql://user:pass@db:5432/proddb
```

### 4.2 Docker容器化

#### 4.2.1 基础镜像

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# 安装依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制代码
COPY . .

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

EXPOSE 5000

CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "4", "app:create_app()"]
```

#### 4.2.2 GPU镜像

```dockerfile
FROM nvidia/cuda:11.8-devel-ubuntu20.04

RUN apt-get update && apt-get install -y \
    python3.10 python3.10-dev python3-pip \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# 设置环境变量
ENV CUDA_VISIBLE_DEVICES=0
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# 安装PyTorch和依赖
RUN pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118
RUN pip install -r requirements.txt

COPY . .

EXPOSE 7860 7861 8080

CMD ["python", "gradio_demo/merged_new.py"]
```

#### 4.2.3 Docker Compose

```yaml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
    volumes:
      - ./data:/app/data
    restart: unless-stopped

  gpu-service:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./ckpt:/app/ckpt
      - ./saved_images:/app/saved_images
    ports:
      - "7860:7860"
      - "7861:7861"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped
```

### 4.3 部署架构

#### 4.3.1 单机部署

```
┌─────────────────────────────────────────┐
│            单机部署架构                  │
├─────────────────────────────────────────┤
│  Nginx (Port 80) → Flask App (Port 5000) │
│                          │               │
│  SQLite ← Redis ← File Storage           │
└─────────────────────────────────────────┘
```

#### 4.3.2 GPU服务器部署

```
┌─────────────────────────────────────────┐
│          GPU服务器部署架构               │
├─────────────────────────────────────────┤
│  Load Balancer (Nginx)                  │
│    │                                    │
│  Web Server ← API Gateway               │
│    │              │                     │
│  Gradio Server ← Model Server           │
│    │              │                     │
│  GPU 计算节点 (DensePose, HumanParsing, │
│              OpenPose, Diffusion)       │
│    │              │                     │
│  Database ← Model Cache ← File Storage   │
└─────────────────────────────────────────┘
```

### 4.4 部署脚本

```bash
#!/bin/bash
# deploy.sh

set -e

echo "开始部署 AI试穿系统..."

# 拉取最新代码
git pull origin master

# 构建Docker镜像
docker-compose build --no-cache

# 重启服务
docker-compose down
docker-compose up -d

# 健康检查
sleep 30
if curl -f http://localhost:5000/health; then
    echo "部署成功！"
else
    echo "部署失败，回滚..."
    git reset --hard HEAD~1
    docker-compose down
    docker-compose up -d
    exit 1
fi

echo "部署完成！"
```

## 5. 监控与运维

### 5.1 监控策略

#### 5.1.1 监控指标

**系统指标**:

- 响应时间: 95%的请求 < 200ms
- 错误率: 每分钟错误请求数 < 5
- CPU使用率 < 70%
- 内存使用率 < 80%

**GPU指标**:

- GPU利用率 > 80%
- GPU温度 < 85°C
- 显存使用率 < 90%

#### 5.1.2 监控实现

```python
# app/monitoring.py
import psutil
import time
from typing import Dict

class AppMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.request_count = 0
        self.error_count = 0
        self.response_times = []
  
    def track_request(self, response_time: float, is_error: bool = False):
        self.request_count += 1
        self.response_times.append(response_time)
        if is_error:
            self.error_count += 1
  
    def get_performance_metrics(self) -> Dict:
        return {
            'request_count': self.request_count,
            'error_count': self.error_count,
            'avg_response_time': sum(self.response_times) / len(self.response_times) if self.response_times else 0,
            'cpu_usage': psutil.cpu_percent(),
            'memory_usage': psutil.virtual_memory().percent,
            'uptime': time.time() - self.start_time
        }
```

### 5.2 性能优化

#### 5.2.1 优化策略

- 数据库查询优化: 使用索引、优化SQL语句
- 缓存优化: 使用Redis缓存热点数据
- 图片处理优化: 使用异步任务处理
- 模型推理优化: 使用TorchScript优化推理速度

#### 5.2.2 GPU监控

```python
# gpu_monitor.py
import torch
import subprocess

def get_gpu_status():
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            memory_allocated = torch.cuda.memory_allocated(i) / (1024**3)
            memory_total = props.total_memory / (1024**3)
            print(f"GPU {i}: {props.name}")
            print(f"Memory: {memory_allocated:.1f}GB / {memory_total:.1f}GB")
    else:
        print("CUDA not available")

def clear_gpu_cache():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("GPU cache cleared")
```

### 5.3 日志管理

```python
# logging_config.py
import logging
import os

def setup_logging():
    log_level = os.environ.get('LOG_LEVEL', 'INFO')
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  
    logging.basicConfig(
        level=getattr(logging, log_level),
        format=log_format,
        handlers=[
            logging.FileHandler('app.log'),
            logging.StreamHandler()
        ]
    )
```

### 5.4 故障排除

#### 5.4.1 常见问题

**问题1: CUDA out of memory**

```bash
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
python -c "import torch; torch.cuda.empty_cache()"
```

**问题2: 端口被占用**

```bash
# 查看端口使用情况
netstat -tulpn | grep :7860
# 终止进程
kill -9 <PID>
```

#### 5.4.2 系统检查清单

**部署前检查**:

- [ ] GPU驱动和CUDA安装
- [ ] Python环境配置
- [ ] 依赖包安装
- [ ] 模型文件下载
- [ ] 端口配置
- [ ] 权限配置

**运行时检查**:

```bash
# 检查GPU状态
nvidia-smi

# 检查服务状态
docker ps

# 检查日志
docker logs <container_name>

# 检查端口
curl http://localhost:7860/health
```

### 5.5 备份与恢复

#### 5.5.1 备份策略

```bash
#!/bin/bash
# backup.sh

BACKUP_DIR="/backup/$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# 备份数据库
cp image_database.db $BACKUP_DIR/

# 备份图片
tar -czf $BACKUP_DIR/saved_images.tar.gz saved_images/

# 备份配置
cp -r config/ $BACKUP_DIR/

echo "备份完成: $BACKUP_DIR"
```

#### 5.5.2 恢复流程

1. 停止服务
2. 恢复数据库文件
3. 恢复图片文件
4. 恢复配置文件
5. 重启服务

### 5.6 安全配置

#### 5.6.1 基础安全

```bash
# 环境变量安全
SECRET_KEY=$(python -c "import secrets; print(secrets.token_hex(32))")
MAX_CONTENT_LENGTH=16777216  # 16MB
ALLOWED_EXTENSIONS=png,jpg,jpeg,gif,webp
```

#### 5.6.2 HTTPS配置

```nginx
server {
    listen 443 ssl;
    server_name your-domain.com;
  
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
  
    location / {
        proxy_pass http://localhost:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## 6. 运维计划

### 6.1 日常运维

#### 6.1.1 监控检查

- 每日检查系统资源使用情况
- 检查应用日志和错误信息
- 验证备份完整性

#### 6.1.2 维护任务

- 定期清理临时文件和日志
- 更新系统补丁和安全更新
- 优化数据库性能
- 检查存储空间使用情况

### 6.2 应急响应

#### 6.2.1 故障响应流程

1. 问题识别和报告
2. 影响评估
3. 应急处理
4. 根因分析
5. 预防措施制定

### 6.3 升级计划

#### 6.3.1 系统升级

- 定期升级Python和依赖包
- 更新AI模型版本
- 优化系统性能
- 扩展功能模块

#### 6.3.2 硬件升级

- 监控硬件性能指标
- 评估升级需求
- 制定升级计划
- 执行升级操作
